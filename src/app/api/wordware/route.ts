import { getUser, updateUser } from '@/actions/actions'
import { TweetType } from '@/actions/types'
import { TwitterAnalysis } from '@/components/analysis/analysis'

/**
 * Maximum duration for the API route execution (in seconds)
 */
export const maxDuration = 300

/**
 * POST handler for the Wordware API route
 * @param {Request} request - The incoming request object
 * @returns {Promise<Response>} The response object
 */
export async function POST(request: Request) {
  const { username, full } = await request.json()
  console.log(`üü¢ Processing request for username: ${username}, full: ${full}`)

  const user = await getUser({ username })

  if (!user) {
    console.log(`‚ùå User not found: ${username}`)
    throw Error(`User not found: ${username}`)
  }

  if (!full) {
    if (user.wordwareCompleted || (user.wordwareStarted && Date.now() - user.createdAt.getTime() < 3 * 60 * 1000)) {
      console.log(`üü† Wordware already started or completed for ${username}`)
      return new Response(JSON.stringify({ error: 'Wordware already started' }), { status: 400 })
    }
  }

  if (full) {
    if (user.paidWordwareCompleted || (user.paidWordwareStarted && Date.now() - user.createdAt.getTime() < 3 * 60 * 1000)) {
      console.log(`üü† Paid Wordware already started or completed for ${username}`)
      return new Response(JSON.stringify({ error: 'Wordware already started' }), { status: 400 })
    }
  }

  function formatTweet(tweet: TweetType) {
    const isRetweet = tweet.isRetweet ? 'RT ' : ''
    const author = tweet.author?.userName ?? username
    const createdAt = tweet.createdAt
    const text = tweet.text ?? ''
    const formattedText = text
      .split('\n')
      .map((line) => `${line}`)
      .join(`\n> `)
    return `**${isRetweet}@${author} - ${createdAt}**

> ${formattedText}

*retweets: ${tweet.retweetCount ?? 0}, replies: ${tweet.replyCount ?? 0}, likes: ${tweet.likeCount ?? 0}, quotes: ${tweet.quoteCount ?? 0}, views: ${tweet.viewCount ?? 0}*`
  }

  const tweets = user.tweets as TweetType[]
  const tweetsMarkdown = tweets.map(formatTweet).join('\n---\n\n')
  console.log(`üü¢ Prepared ${tweets.length} tweets for analysis`)

  const promptID = full ? process.env.WORDWARE_FULL_PROMPT_ID : process.env.WORDWARE_ROAST_PROMPT_ID
  console.log(`üü¢ Using promptID: ${promptID}`)

  console.log('üü¢ Sending request to Wordware API')
  const runResponse = await fetch(`https://app.wordware.ai/api/released-app/${promptID}/run`, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      Authorization: `Bearer ${process.env.WORDWARE_API_KEY}`,
    },
    body: JSON.stringify({
      inputs: {
        tweets: `Tweets: ${tweetsMarkdown}`,
        profilePicture: user.profilePicture,
        profileInfo: user.fullProfile,
        version: '^1.0',
      },
    }),
  })

  const reader = runResponse.body?.getReader()
  if (!reader || !runResponse.ok) {
    console.log('üü£ | ERROR | Wordware API Error:', runResponse.status, await runResponse.text())
    return new Response(JSON.stringify({ error: 'No reader' }), { status: 400 })
  }

  console.log('üü¢ Received successful response from Wordware API')

  console.log('üü¢ Updating user to indicate Wordware has started')
  await updateUser({
    user: {
      ...user,
      [full ? 'paidWordwareStarted' : 'wordwareStarted']: true,
      [full ? 'paidWordwareStartedTime' : 'wordwareStartedTime']: new Date(),
    },
  })

  const decoder = new TextDecoder()
  let buffer: string[] = []
  let finalOutput = false
  let chunkCount = 0
  let lastChunkTime = Date.now()
  let generationEventCount = 0
  const FORCE_FINAL_OUTPUT_AFTER = 50 // Force finalOutput after this many chunks if not set

  function logMemoryUsage() {
    const used = process.memoryUsage()
    console.log('üß† Memory usage:')
    for (const key in used) {
      console.log(`${key}: ${Math.round(used[key as keyof NodeJS.MemoryUsage] / 1024 / 1024 * 100) / 100} MB`)
    }
  }

  async function saveAnalysisAndUpdateUser(user, value, full) {
    console.log(`üü¢ Attempting to save analysis. Full: ${full}, Value received:`, JSON.stringify(value));
    
    const statusObject = full
      ? {
          paidWordwareStarted: true,
          paidWordwareCompleted: true,
        }
      : { wordwareStarted: true, wordwareCompleted: true };

    try {
      let analysisToSave;
      if (full) {
        // For full analysis, overwrite the entire analysis
        analysisToSave = value.values.output;
      } else {
        // For free analysis, only update specific fields
        analysisToSave = {
          ...user.analysis, // Keep existing analysis
          roast: value.values.output.roast,
          emojis: value.values.output.emojis,
          // Add any other fields that should be updated for free analysis
        };
      }

      await updateUser({
        user: {
          ...user,
          ...statusObject,
          analysis: analysisToSave,
        },
      });
      console.log(`üü¢ Analysis saved to database. Full: ${full}`);
    } catch (error) {
      console.error('‚ùå Error parsing or saving output:', error);
      const failureStatusObject = full
        ? {
            paidWordwareStarted: false,
            paidWordwareCompleted: false,
          }
        : { wordwareStarted: false, wordwareCompleted: false };
      await updateUser({
        user: {
          ...user,
          ...failureStatusObject,
        },
      });
      console.log(`üü† Updated user status to indicate failure. Full: ${full}`);
    }
  }

  const stream = new ReadableStream({
    async start(controller) {
      console.log('üü¢ Stream processing started');
      let lastProcessedValue = null;
      try {
        while (true) {
          const { done, value } = await reader.read();

          if (done) {
            console.log('üü¢ Stream reading completed');
            if (lastProcessedValue) {
              console.log('üîÑ Attempting to save analysis at the end of stream.');
              await saveAnalysisAndUpdateUser(user, lastProcessedValue, full);
            }
            controller.close();
            return;
          }

          const chunk = decoder.decode(value);
          chunkCount++;
          const now = Date.now();
          console.log(`üü£ Chunk #${chunkCount} received at ${new Date(now).toISOString()}, ${now - lastChunkTime}ms since last chunk`);
          lastChunkTime = now;

          if (chunkCount <= 5) {
            console.log(`üîç Full chunk content: ${chunk}`);
          }

          if (chunkCount % 10 === 0) {
            console.log(`üü† Buffer size: ${buffer.join('').length} characters`);
            logMemoryUsage();
          }

          for (let i = 0, len = chunk.length; i < len; ++i) {
            const isChunkSeparator = chunk[i] === '\n';

            if (!isChunkSeparator) {
              buffer.push(chunk[i]);
              continue;
            }

            const line = buffer.join('').trimEnd();

            try {
              const content = JSON.parse(line);
              const value = content.value;

              if (value.type === 'generation') {
                console.log(`üîµ Generation event: ${value.state} - ${value.label}`);
                generationEventCount++;
                if (value.state === 'start') {
                  if (value.label === 'output') {
                    finalOutput = true;
                    console.log('üîµ finalOutput set to true');
                  }
                } else {
                  if (value.label === 'output') {
                    finalOutput = false;
                    console.log('üîµ finalOutput set to false');
                  }
                }
              } else if (value.type === 'chunk') {
                controller.enqueue(value.value ?? '');
                console.log(`üü¢ Enqueued chunk: ${(value.value ?? '').slice(0, 50)}...`);
              } else if (value.type === 'outputs') {
                console.log('‚ú® Received final output from Wordware. Now parsing');
                lastProcessedValue = value;
                await saveAnalysisAndUpdateUser(user, value, full);
              }

              if (!finalOutput && chunkCount >= FORCE_FINAL_OUTPUT_AFTER) {
                console.log(`üî¥ Forcing finalOutput to true after ${FORCE_FINAL_OUTPUT_AFTER} chunks`);
                finalOutput = true;
              }
            } catch (error) {
              console.error('‚ùå Error processing line:', error, 'Line content:', line);
            }

            buffer = [];
          }
        }
      } catch (error) {
        console.error('‚ùå Critical error in stream processing:', error);
      } finally {
        console.log('üü¢ Stream processing finished');
        console.log(`üü¢ Total chunks processed: ${chunkCount}`);
        console.log(`üü¢ Total generation events: ${generationEventCount}`);
        if (lastProcessedValue) {
          // Attempt to save analysis if it wasn't saved during the process
          console.log('üîÑ Attempting final save of analysis.');
          await saveAnalysisAndUpdateUser(user, lastProcessedValue, full);
        }
        reader.releaseLock();
      }
    },
  });

  console.log('üü¢ Returning stream response')
  return new Response(stream, {
    headers: { 'Content-Type': 'text/plain' },
  })
}
